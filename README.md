# nexMart Data Analyst Coding Challenge

This repository contains solution for the nexMart Data Analyst take-home assignment.  
All files, notebooks, and dashboards were created after downloading the assignment data, setting up this repository, and completing each task as instructed.

---

## My Submission Scenario

I downloaded the assignment data, created a new GitHub repository, performed data cleaning and analysis using Python and SQL, built a Power BI dashboard, and organized all files and documentation as required for the nexMart Data Analyst coding challenge.

---

## How to Reproduce

### 1. Download or Clone This Repository

Download this repository as a ZIP and extract, or use GitHub’s “Clone” button if you prefer.

### 2. Install Dependencies

## Python and SQL Packages Used

### Python Packages

The following Python packages are required:


- **pandas**: Data manipulation and analysis
- **numpy**: Numerical operations
- **math**: Mathematical functions
- **seaborn**: Data visualization
- **matplotlib**: Plotting graphs
- **warnings**: Handling warning messages
- **pandasql**: Running SQL queries on pandas DataFrames

### SQL

- **pandasql** enables running standard SQL queries (SQLite syntax) directly on pandas DataFrames within Python notebooks.
- No separate SQL server or installation is required; all queries are executed in-memory.

---

### 3. Run the Data Pipeline

- Open `notebooks/data_pipeline.ipynb` in Jupyter.
- Run all cells to:
  - Load raw data from `data/`
  - Clean and normalize data
  - Export cleaned data as `product_catalog_cleaned.csv` in `data/`

### 4. Run SQL Analysis

- Open `notebooks/product_catalog_sql_analysis.ipynb`.
- Run all cells to:
  - Execute SQL queries using pandasql
  - View answers, results, and explanations for assignment questions

### 5. View Power BI Dashboard

- Open `dashboard/nexmart_dashboard.pbix` in Power BI Desktop.
- If prompted, point the data source to your local `data/product_catalog_cleaned.csv`.

---
## File Descriptions

| File/Folder                               | Description                                         |
|-------------------------------------------|-----------------------------------------------------|
| `dashboard/nexmart_dashboard.pbix`        | Power BI dashboard (one-pager)                      |
| `data/manufacturers.csv`                   | Raw manufacturer data                               |
| `data/product_descriptions.csv`            | Raw product descriptions data                       |
| `data/product_properties.csv`              | Raw product properties data                         |
| `data/product_catalog_cleaned.csv`         | Cleaned and standardized product catalog data generated by the data pipeline; used as input for SQL analysis and dashboard |
| `data/.ipynb_checkpoints/`                  | Jupyter notebook checkpoints                        |
| `notebooks/data_pipeline.ipynb`             | Data cleaning and pipeline (Python)                 |
| `notebooks/product_catalog_sql_analysis.ipynb` | SQL analysis and assignment answers           |
| `notebooks/pandas_sql_sample.ipynb`         | Sample notebook demonstrating pandasql usage        |
| `.gitattributes`                            | Git attributes configuration                        |
| `.gitignore`                                | Git ignore rules                                    |
| `README.md`                                 | This documentation                                  |

---

## Assignment Approach

1. **Data Processing (Python + Pandas)**
   - Cleaned join columns, normalized bad values, exported cleaned dataset.
2. **SQL Analysis**
   - Identified manufacturers with highest improvement potential.
   - Analyzed data quality per variable and manufacturer.
   - Provided additional insights.
3. **Power BI**
   - One-page dashboard summarizing key findings for business and technical users.

---

## Production-Readiness

For a production environment, the following would be required:
- Automated ETL/data ingestion
- Logging and monitoring
- CI/CD pipeline
- Data validation and alerting
- In production, data files should be fetched directly from a server URL, not loaded manually from local files

---

![image](https://github.com/user-attachments/assets/8371f9d3-5e3b-482d-a06f-156871a70db6)

**Thank you for reviewing my submission.**




